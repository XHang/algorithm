# 算法笔记
# 一： 基础知识
1. 什么是约数，什么是倍数

   如果数a能被数b整除，例如8能被4整除。

   那么8是4的倍数

   4是8的约数

2. 几个整数共有的约数，叫做这几个数的公约数，其中最大的一个，叫做这几个数的最大公约数

   例如`12`,`16`它们共有的约数是

   `1`,`2` ,`4`  那它们的最大公约数就是4，一般记为`(12，16）=4`  

   > 其实1可以作为所有整数的约数，发现没？


# 二：基础算法

## 2.1 排序相关

排序相关算法有几种

1. 选择排序 ：算法思路

   首先取最前的元素和其余元素比较，如果最前的元素比那个元素更大，则不需交换位置，否则就要把那个元素的位置调到最前。

   图示

   ![选择排序](https://raw.githubusercontent.com/XHang/algorithm/master/src/main/resources/%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F.jpg)

2: 冒泡排序

跟选择排序大致一样，就是比较-交换，然后每一轮比较后，末尾或者开头的元素总是最值

但是冒泡排序比较的对象时是相邻元素

图示

![冒泡排序](<https://raw.githubusercontent.com/XHang/algorithm/master/src/main/resources/%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F.jpg>)



## 2.2 snowflake 算法

这是一个在分布式集群中，生成全局、唯一、且递增的ID的一个算法

目前在Twitter采用

它总共有64位组成。其中

第一位永远是0，没有实际作用

1-41位是时间戳，精确到毫秒。（总共41位）

42-52位是工作机器ID，其中高5位是数据中心ID，第五位是工作节点ID。多的话可以容纳1024个节点

缺点：如果生成器在生成之前，系统时钟回拨过，则有ID重复的危险。（因为生成器不知道它上一次生成的时间点）
如果生成器已经生成，但是系统时钟也回拨了，这倒没问题，生成器会抛异常。


> （总共10位）

53-64位是序列号，用来记录同毫秒产生的不同ID(总共12位)

该算法可以保证

1. 生成的ID是递增的
2. 不会出现重复ID(通过工作机器ID来保证)

为了保证你能看懂算法的内容，我们来复习一下底层的数字运行-位运算

### 2.2.1 二进制基础

**一个字节由8个0或1的二进制组成**

而在计算机中，字符都是以ASCII码存储的。

### 2.2.2左移

以`3 << 2`为例

表面意思是将数字3想左移动两位

运算过程是，首先将3变成二进制数字：`0000 0000 0000 0000 0000 0000 0000 0011`

> 为什么前面这~么~多~个~0?
>
> 因为我假设你正在用4个字节的存储空间进行运算。所以总共是32个0或者1
>
> 所以扩展起来，就酱紫啦
>
> 你要换成java的int计算，它是8个字节，总共64个0或者1，我这小地方可容不下
>
> 顺带一提，你试着把64个二进制补全，转成十进制，它就是java下int的最大值！

然后将里面的每一位向左移动两位，高位的丢弃，低位的补0.结果是

`0000 0000 0000 0000 0000 0000 0000 1100`

转成十进制，12.就是它了

顺带说明：左移1位的话，就是`原值*2`，左移2位的话，就是`原值*4`

以此类推

`原值*（2^左移的个数）`

### 2.2.3 负数的二进制表现形式

其实很简单啦。假设你要把一个正数改为负数。

1. 无论这个正数是什么进制，首先把它变成二进制
2. 取反，假设变成二进制后是0000 0010，取反后就变成了1111 1101
3. 再加1，变成1111 1110

### 2.2.4 二进制运算的几个特点

1. `-1L ^ (-1L << bits);`  此算式可以算出bits个二进制位能表示的最大值是多少

2. `sequence = (sequence + 1) & sequenceMask;`  可以保证sequence递增到sequenceMask值时，再次递增，会回到0从头开始计数

   > 如果不加这个数的话，一个数递增到溢出后，会从最大值的负数往后递减。。。java是酱紫的
   
3. 想组合两个二进制，请用`|`运算，比如`111000`,`000111 `要组合成`111111`请用`|`运算

## 2.2.5： snowflake的思路

1. 创建生成器，因为生成器有状态需要保存：工作机的ID,数据中心的ID,以及毫秒内的序列号，用于毫秒内的序列号生成。创建过程需要校验，数据中心ID和工作机的ID不能为负数，且不能超过最大值，序列号反而不用校验。

2. 调用生成器的生成ID方法

   运算步骤

   1. 获取当前时间戳

      ​	1. 如果该时间戳小于上次运行的时间戳，要不就是机器时光穿梭了，要么就是机器的时钟回拨了，这两种情况都有可能使生成的ID重复，所以这种情况要抛出异常。不允许生成ID

      > 如果生成器在生成之前，系统时钟被回拨了，且在回拨的那段时间里，已经用过生成器生成ID
      >
      > 那么这次生成器再次生成的ID，则会有ID重复的危险。

      ​	2. 如果当前时间戳等于上次运行的时间戳，说明上次生成ID和这次生成ID的时间差在毫秒内。

      ​	这个时候ID里面的组成部分，时间戳就会重复。

      ​	这个时候，将序列号+1，用序列号来保证即使时间戳一样，最后生成ID也和上次生成的ID不一样

      > 如果序列化+1之后溢出了，变成0（正常溢出变成负数哦，这里用了位运算的特性）
>
      > 仍有可能导致生成的ID重复了（想象一下，一毫秒内，序列号全都被用来生成ID了）
      >
      > 为了避免这种极端情况，可以让cpu空转到下一个毫秒，使用下一个时间戳来作为ID的唯一性保障

      3. 如果当前时间戳大于上一次运行的时间戳，可以使用时间戳而不是序列号来作为ID唯一性保障。
      
         这个时候，序列号可以置0，使ID递增幅度不会太大，同时也尽可能更多的利用序列号生成ID
      
         不要总出现溢出的情况

   2. 对ID的各个组成部分进行位移运算，用`&`运算来组合各部分的二进制，形成新的ID,并返回。
   
      > 时间戳要减去初值，主要是省去一定的位数，并且可以人为的初始时间戳部分的值
      >
      > 充分占用时间戳的部分

   > 其实吧，里面用了这么多的二进制计算，只是为了位移运算，简单的移动位置罢了。
   >
   > 你要用容器包裹起来，移动也是没问题的。只不过，效率低且要绕远路

### 2.2.6 BitMap算法

老实说，我不觉得它是一种算法。只是巧用二进制的每一位，去存储我们想要的信息罢了

这样可以节省大量空间。而且还可以

1. 快速排序
2. 快速去重
3. 快速查询
4. Bloom Filter(布隆过滤器)

要做到这一点，我们首先尝试把数据存储在BitMap中

这样做的关键是：二进制里面的每一个位，都存储一个数字

> 要把二进制当成一个容器，每一位都是一个小格子。
>
> 0代表这个小格子是空的
>
> 1代表这个小格子有东西
>
> 每一个小格子，都对应到实际业务的一条记录

假设现在有1,3,7,6 数字，要用bitmap存储起来

那么首先创建一个10位二进制数并置0

`0000000000`

按照数字的顺序，将二进制数从右到左数起，将对应的位数置1

存储结果是

| 0    | 0    | 1     | 1     | 0    | 0    | 1     | 0    | 1     | 0    |
| ---- | ---- | ----- | ----- | ---- | ---- | ----- | ---- | ----- | ---- |
|      |      | 代表7 | 代表6 |      |      | 代表3 |      | 代表1 |      |

也就是`0011001010`了

有了这个存储结构，我们就可以进行

1. 快速排序：把上面的二进制位为1按从右到左的顺序输出来，这样就排好序了
2. 快速去重：由于每一位数字只有唯一一个格子空间，所以当我们把bitMap起来后，实际就已经完成了去重了
3. 快速查询：查询数字对应的bitmap是否1还是0，就可以知道它存不存在了

但是也有缺点

​	比如我现在有1,3,5,6,7,9  这么多数字，但是存在Bitmap的仅1,3,5,6 

我无法通过Bitmap查找出有哪些数据未存进来。

将每一个bit取反是行不通的，因为有些存储空间根本没使用到，而我实际上只有7,9没有存进去

**介绍一下Google的BitMap算法**

首先要知道的是，采用Bitmap存储方式，是数据全部存在二进制数里面的。

而现今的编程语言，如java，一个long最多也就64个二进制数可以存储。换句话说，最多存储64个数字

如果要存超过64的数字呢，只能扩充long了。

所以在Google算法中，数据都是存储在long数组里面的，一个long数组就是一个word，可以存储64个数字

现在来说说BitMap存储方式的弊端，就是当要存储的数字大过先前存储的数字很多的话，就会导致会创建很多的空word。

Google的BitMap算法会统计，当要存储的位数大过先前存储的数字很多的话，会只创建两个word，前一个word记录中间省略了多少位等信息，后面才是真实记录存储的位数

大致就是这样吧。

现在能理解，将来能不能理解，就不好说了。。

**接下来时候布隆算法**

它是基于bitmap的存储结构，判断数据是否在大量数据以内的一种方法。

由于采用位运算，速度还算蛮快的。。

假设现在有很多的字符串，存在集合A里面，现在有一个字符串，要判断是该字符串是否在里面。

首先

对集合A里面的每一个字符串，用三个的哈希函数，做哈希值运算

将得到的三个哈希值，存储在bitmap中。

对即将要判断的字符串也做如上处理，得到三个哈希值。

如果这三个哈希值都在bitmap存在了，则说明重复。

以上。

弊端，哪怕是三次哈希运算，仍然有可能哈希冲突哦，带了的结果就是原本不在集合内的字符串。

被误判为在集合内。

对错误率要求为0的应用不要考虑哒

>有空实现那两个鬼东西
>
>原理基本理解。
>
>至于Google的bitmap算法，算了，了解下就可以了











# 三： 算法第四版笔记

## 3.1  基础编程模型
1. 有时候，一些代码上的加减乘除运算，其结果，未必准确
    比如说，在java上，定义一个计算式`5/3`其结果将是1，而非1.666...
    又比如说，计算`5.0/3.0`其结果是`1.66666666667` 

  这两个结果都不是准确性的，属于估算。


# 四：问题
```
        System.out.println(Long.toBinaryString((-1)<<32));
        System.out.println(Long.toBinaryString((-1L)<<32));
```
计算得来的结果分别是  
```
1111111111111111111111111111111111111111111111111111111111111111
1111111111111111111111111111111100000000000000000000000000000000
```
第二个结果我们能想到，这是位移运算的特点，移动过去的字符溢出丢弃，前面的补0
第一个结果也应该如此，然而并没有。这是因为编译器的特性。
当移动的位数超过了该类型的最大位数（int的最大位数是31），会对移动的位数进行对2取模。
移动的位数是32，对2取模后是0，所以实际只移动了0位，根本没变化嘛。
就酱


